---
title: "UG_HLM"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(lme4)
library(ggplot2)
library(GGally)
library(plyr)
library(Matrix)
library(nlme)
library(readxl)
library(reshape2)
library(VIF)
library(numDeriv)
library(MuMIn)
library(HLMdiag)
library(DHARMa)
library(bitops)
library(nloptr)
library(optimx)
library(dfoptim)
library(emmeans)
library(afex)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. 

# Import and Clean data
```{r}
#task <- read.csv("/Users/kezhang/ownCloud/Suicide_UG/UG_clean_updated/ug_all_task_data.csv")
#demo <- read_excel("/Users/kezhang/ownCloud/Suicide_UG/UG_clean_updated/ug_demog.xlsx")
#question <- read_excel("/Users/kezhang/ownCloud/Suicide_UG/UG_clean_updated/ug_questionnaire.xlsx")

task <- read.csv("C:\\Users\\ke\\ownCloud\\Suicide_UG\\UG_clean_updated\\ug_all_task_data.csv")
demo <- read_excel("C:\\Users\\ke\\ownCloud\\Suicide_UG\\UG_clean_updated\\ug_demog.xlsx")
question <- read_excel("C:\\Users\\ke\\ownCloud\\Suicide_UG\\UG_clean_updated\\ug_questionnaire.xlsx")

demoQuestion <- merge(demo, question, on = "ID")
allData <- merge(task, demoQuestion, on = "ID")
allData$totalStake <- allData$PlayerProposedAmount + allData$OpponentProposedAmount

allData <- rename(allData, c("HOUSEHOLD INCOME" = "HouseholdIncome", "HRSD NO SUI" = "HRSD_NO_SUI", "PER CAPITA INCOME" = "IncomePerCapita", "MMSE TOTAL" = "MMSE"))

allData$Fairness_score <- as.factor(allData$Fairness_score)
allData$ID <- as.factor(allData$ID)
allData$AcceptOffer <- as.factor(allData$AcceptOffer)
allData$PROTECT2AGE <- as.numeric(allData$PROTECT2AGE)

#allData$group4 <- ordered(allData$group4, levels = c("attempter", "ideator", "depression", "control"))
#allData$group5 <- ordered(allData$group5, levels = c("Control", "AttempterHL", "AttempterLL", "ideator", "depression"))

# check variable types
sapply(allData["PROTECT2AGE"], class)
```

## Is fairness ratio orthogonal with stake size?
```{r}
task$totalStake <- task$PlayerProposedAmount + task$OpponentProposedAmount
corr <- cor(task$Fairness_score, task$PlayerProposedAmount)
corr1 <- cor(task$Fairness_score, task$OpponentProposedAmount)
corr2 <- cor(task$Fairness_score, task$totalStake)
print(corr)
print(corr1)
print(corr2)
```

# Demographics and questionnaires descriptive plots
## Correlations between continous predictors
```{r}
ggpairs(demoQuestion[, c("PROTECT2AGE", "HOUSEHOLD INCOME", "HRSD NO SUI", "DRS", "EDUCATION")])

cor.test(allData$MMSE, allData$EDUCATION)
```

## By subject type
```{r}
# by group "subject type"
tmp_subject1 <- melt(demoQuestion[, c("group4", "PROTECT2AGE", "HOUSEHOLD INCOME", "HRSD NO SUI", "DRS")], id.vars = "group4")
tmp_subject2 <- melt(demoQuestion[, c("group5", "PROTECT2AGE", "HOUSEHOLD INCOME", "HRSD NO SUI", "DRS")], id.vars = "group5")

plt_subject1 <- ggplot(tmp_subject1, aes(factor(group4), y = value, fill = factor(group4))) +
  geom_boxplot() +
  facet_wrap(~ variable, scales = "free_y") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

plt_subject2 <- ggplot(tmp_subject2, aes(factor(group5), y = value, fill = factor(group5))) +
  geom_boxplot() +
  facet_wrap(~ variable, scales = "free_y") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

print(plt_subject1)
print(plt_subject2)
```

## By gender
```{r}
tmp_gender <- melt(demoQuestion[, c("GENDERTEXT", "PROTECT2AGE", "HOUSEHOLD INCOME", "HRSD NO SUI", "DRS")], id.vars = "GENDERTEXT")
plt_gender <- ggplot(tmp_gender, aes(factor(GENDERTEXT), y = value, fill = factor(GENDERTEXT))) +
  geom_boxplot() +
  facet_wrap(~ variable, scale = "free_y") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
print(plt_gender)
```

## By race
```{r}
tmp_race <- melt(demoQuestion[, c("RACETEXT", "PROTECT2AGE", "HOUSEHOLD INCOME", "HRSD NO SUI", "DRS")], id.vars = "RACETEXT")
plt_race <- ggplot(tmp_race, aes(factor(RACETEXT), y = value, fill = factor(RACETEXT))) +
  geom_boxplot() +
  facet_wrap(~ variable, scale = "free_y") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
print(plt_race)
```

## By ethinicity
```{r}
tmp_eth <- melt(demoQuestion[, c("ETHNICITYTEXT", "PROTECT2AGE", "HOUSEHOLD INCOME", "HRSD NO SUI", "DRS")], id.vars = "ETHNICITYTEXT")
plt_eth <- ggplot(tmp_eth, aes(factor(ETHNICITYTEXT), y = value, fill = factor(ETHNICITYTEXT))) +
  geom_boxplot() +
  facet_wrap(~ variable, scale = "free_y") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
print(plt_eth)
```

## By marriage
```{r}
tmp_marr <- melt(demoQuestion[, c("MARITALTEXT", "PROTECT2AGE", "HOUSEHOLD INCOME", "HRSD NO SUI", "DRS")], id.vars = "MARITALTEXT")
plt_marr <- ggplot(tmp_marr, aes(factor(MARITALTEXT), y = value, fill = factor(MARITALTEXT))) +
  geom_boxplot() +
  facet_wrap(~ variable, scale = "free_y") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
print(plt_marr)
```

## stake size
```{r}
# stake size, fairness, reappraisal and y
p <- ggplot(allData, aes(x = allData$totalStake, y = as.numeric(AcceptOffer)-1, color=Fairness_score)) +
  stat_smooth(method = "glm", method.args = (list(family = "binomial")), formula = y~x, alpha = 0.2, size = 2, aes(fill = AcceptOffer)) +
  geom_point(position = position_jitter(height = 0.03, width = 0)) +
  xlab("total stake") +
  ylab("Pr(accept)")

p + facet_grid(. ~ReappraisalDirection)
```

# Whether HLM is needed?
## Intercept only
```{r}
interceptOnly <- glm(task$AcceptOffer ~ 1, family = binomial, data = task)
print(summary(interceptOnly))
```

## Null model: random intercept only
```{r}
randomInterceptOnly <- glmer(task$AcceptOffer ~ 1 + (1|ID), data = task, family = binomial)
print(summary(randomInterceptOnly))
```
By adding the ID (nested), the AIC (1|D) is smaller than the AIC (1). So HLM is necessary. 

The variance of the intercept in the *null model is 1.157*. That is the variance can't be explained by the random effect of ID. Compare the variance with more complicated models. If the intercept variance gets smaller, that is an indication of the additional predictors adding more explanation to the DV.

##  Intraclass Correlation (ICC)
Test if HLM is needed: whether there is variation over the level 2 variable (participant ID). If the ICC > 0, then HLM is needed.
```{r}
ICC_model <- function(modelName) {
  tau_null <- as.numeric(lapply(summary(modelName)$varcor, diag))
  sigma_null <- as.numeric(attr(summary(modelName)$varcor, "sc")^2)
  ICC_null <- tau_null/(tau_null + sigma_null)
  return(ICC_null)
}

cat("ICC is", ICC_model(randomInterceptOnly))
```
The ICC > 0, the HLM is needed.

# Level 1 predictor only models

## Social framing
```{r}
##random intercept only
m_framing_intercept <- glmer(allData$AcceptOffer ~ ReappraisalDirection + (1|ID), data = allData, family = binomial)
print(summary(m_framing_intercept))

##random intercept and slope
m_framing_slope <- glmer(allData$AcceptOffer ~ ReappraisalDirection + (ReappraisalDirection|ID), data = allData, family = binomial)
print(summary(m_framing_slope))

##best fit
anova(m_framing_intercept, m_framing_slope)
```
There is considerable variation in the intercept and slopes of the framing context. So use the slope model.

But the intercept variances by adding the framing predictor increases, compare to the null model. Worsen?

## Total stake size
```{r}
m_stakeSize_intercept <- glmer(allData$AcceptOffer ~ totalStake + (1|ID), data = allData, family = binomial)
print(summary(m_stakeSize_intercept))

m_stakeSize_slope <- glmer(allData$AcceptOffer ~ totalStake + (totalStake|ID), data = allData, family = binomial)
print(summary(m_stakeSize_slope))

anova(m_stakeSize_intercept, m_stakeSize_slope)

```
Acceptance does not vary across stake size by slope. So use the intercept only model.

But the intercept variances by adding the stack size predictor increases, compare to the null model. Worsen?


## Fairness score(categorical)
```{r}
m_fair_intercept <- glmer(allData$AcceptOffer ~ Fairness_score + (1|ID), data = allData, family = binomial)
print(summary(m_fair_intercept))

# converge issue
m_fair_slope <- glmer(allData$AcceptOffer ~ Fairness_score + (Fairness_score|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))
print(summary(m_fair_slope))

## try different optimizers
### optimizer = c("bobyqa","Nelder_Mead", "nlminbw",  "nmkbw", "optimx", "nloptwrap")
m_fair_slope_all <- all_fit(m_fair_slope)

anova(m_fair_intercept, m_fair_slope)
```
The slope model is better than the intercept only model for fairness score.

## Random intercept & fixed slope\predictors (Level 1 predictors only)
**Model**
$$logit(accept) = Reappraisal\,Direction + total\,stake + Fairness\,score + 1|ID$$

The predictors are scaled: converted to z-scores. The global model is: 
```{r}
m_level1 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + (1|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

m_level1_all <- all_fit(m_level1)
summary(m_level1)
```
The above model converges in optimizer: bobyqa, Nelder_Mead, optimx.nlminb. The intercept variance of the global model is larger than the null model.  

Explore all combinations of predictors, and list the alternatives by by the size of AIC from the small to large. The best model is selected by the smallest AIC.

The summary of all alternative models is:
```{r}
#options(na.fail = "na.fail")
d_m_level1 <- dredge(global.model = m_level1, rank = "AICc")
print(d_m_level1)
```

Model 4 and 8 are both best fit model. Although Model 4 has the smallest AIC, but since they have dAIC (delta) < 2. 

Model 4: $$logit(accept) = Fairness\,score + ReappraisalDirection + (1 | ID)$$
Model 8: $$logit(accept) = Fairness\,score + ReappraisalDirection + scale(totalStake) + (1 | ID)$$

### Best fit model
```{r}

print(get.models(d_m_level1, subset = delta < 2))

# the smallest AIC
d_m_level1_1 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + Fairness_score + (1|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))
summary(d_m_level1_1)

# the second smallest AIC
d_m_level1_2 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + (1|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

# best model
anova(d_m_level1_1, d_m_level1_2)

```
The models with/without the predictor $totalStake$ are not significantly differ. So choose the parsimonious model with the fewer predictors: Model 4 (without $totalStake$) at the level 1 only predictors.

## Random intercept & random slope\predictors (Level 1 only): *Reappraisal Direction*

**Model**
$$logit(accept) = Reappraisal\,Direction + total\,stake + Fairness\,score + Reappraisal\,Direction|ID$$
The global model of the random intercept and slope (Reappraisal Direction) is:
```{r}
m_level1_slope1 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + (ReappraisalDirection|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

summary(m_level1_slope1)

```

The summary of all alternative models is, ranked from AICc low to high:
```{r}
m_d_level1_slope1 <- dredge(global.model = m_level1_slope1, rank = "AICc")
print(m_d_level1_slope1)
```
Model 8 and 4 are both best fit model. Although Model 8 has the smallest AIC, but since they have dAIC (delta) < 2. The best fits models are:

Model 8: $$logit(accept) = Fairness\,score + Reappraisal\,Direction + scale(total\,Stake) + (Reappraisal\,Direction | ID)$$
Model 4: $$logit(accept) = Fairness\,score + Reappraisal\,Direction + (Reappraisal\,Direction | ID)$$


```{r}
print(get.models(m_d_level1_slope1, subset = delta < 2))

# the smallest AIC
m_d_level1_slope1_1 <- glmer(allData$AcceptOffer ~ Fairness_score + ReappraisalDirection + scale(totalStake) + (ReappraisalDirection|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")


summary(m_d_level1_slope1_1)

# the second smallest AIC
m_d_level1_slope1_2 <- glmer(allData$AcceptOffer ~ Fairness_score + ReappraisalDirection  + (ReappraisalDirection|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")


# best model
anova(m_d_level1_slope1_1, m_d_level1_slope1_2)
```
The two models are not significantly different from each other. So choose the parsimonious model: model 4.

## Random intercept & random slope\predictors (Level 1 only): *Fairness score*

**Model**
$$logit(accept) = Reappraisal\,Direction + total\,stake + Fairness\,score + Fairness\,score|ID$$
The global model of the random intercept and slope (fairness score) is:
```{r}
m_level1_slope2 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + (Fairness_score|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

summary(m_level1_slope2)

```

The summary of all alternative models is, ranked from AICc low to high:
```{r}
m_d_level1_slope2 <- dredge(global.model = m_level1_slope2, rank = "AICc")
print(m_d_level1_slope2)
```
Model 4 and 8 are both best fit model. Although Model 8 has the smallest AIC, but since they have dAIC (delta) < 2. The best fits models are:

Model 4: $$logit(accept) = Fairness\,score + ReappraisalDirection + (Fairness\,score | ID)$$

Model 8: $$logit(accept) = Fairness\,score + ReappraisalDirection + scale(total\,stake) + (Fairness\,score | ID)$$

```{r}
print(get.models(m_d_level1_slope2, subset = delta < 2))

# the smallest AIC
m_d_level1_slope2_1 <- glmer(allData$AcceptOffer ~ Fairness_score + ReappraisalDirection + (Fairness_score|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

# the second smallest AIC
m_d_level1_slope2_2 <- glmer(allData$AcceptOffer ~ Fairness_score + ReappraisalDirection + scale(totalStake) + (Fairness_score|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

anova(m_d_level1_slope2_1, m_d_level1_slope2_2)
```
The two models are not significantly differ. But choose the parsimonious model: model 4.

## Random intercept & random slope\predictors (Level 1 only): *Fairness score*, *reappraisal*

**Model**
$$logit(accept) = Reappraisal\,Direction + total\,stake + Fairness\,score + Reappraisal\,Direction|ID +\\ Fairness\, score |ID$$

```{r}
# global models
m_level1_slope3 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + (Fairness_score|ID) + (ReappraisalDirection|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

m_level1_slope3_all <- all_fit(m_level1_slope3)

summary(m_level1_slope3_all)
```
The models can't be converged by all optimizers and at the max iterations. Abandon?

#RUNNNNNN______________________________________
all alternative models:
```{r}
m_d_level1_slope3 <- dredge(global.model = m_level1_slope3, rank = "AICc")
print(m_d_level1_slope3)

# Get best models
print(get.models(m_d_level1_slope3, subset = delta < 2))

# the smallest AIC
m_d_level1_slope3_1 <- get.models(m_d_level1_slope3,1)[[1]]

anova(m_d_level1_slope1_1, m_d_level1_slope2_1, m_d_level1_slope3_1)
```

## Compare level 1 models
Random intercept & fixed slope vs. Random intercept & random slope
```{r}
anova(m_d_level1_slope2_1, m_d_level1_slope1_1, d_m_level1_1)
anova(m_d_level1_slope2_1, m_d_level1_slope1_1)

anova(m_d_level1_slope1_1, d_m_level1_1)
anova(m_d_level1_slope2_1, d_m_level1_1)
```
The random intercept and slope models ($fairness\,score|ID$ & $reappraisal\,direction|ID$) ware not significantly different from each other. But significantly better than the random intercept and fixed slope models.

# Level 2 predictor model
How does each level 2 predictor influence the acceptance? Are they significant variable for the offer acceptance?

**Model**
$$logit(accept) = predictors + Reappraisal\,Direction|ID$$

## subject type (group 4)
```{r}
m_group4 <- glmer(allData$AcceptOffer ~ group4 + (1|ID), data = allData, family = binomial)
print(summary(m_group4))

# plot
ggplot(allData, aes(x = group4, y = AcceptOffer)) +
  geom_point(shape = 1, position = position_jitter(width = 0.05, height = 0.05)) +
  stat_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE)
```
The group factor does influence the DV, because of the smaller intercept variance than the null.

## subject type (group 5)
```{r}
m_group5 <- glmer(allData$AcceptOffer ~ group5 + (1|ID), data = allData, family = binomial)
print(summary(m_group5))

```
The group factor does influence the DV, because of the smaller intercept variance than the null.

## age
```{r}
m_age <- glmer(allData$AcceptOffer ~ PROTECT2AGE + (1|ID), data = allData, family = binomial)
print(summary(m_age))

```
The age factor does not influence the DV, because of the larger intercept variance than the null.

## HRSD NO SUI
```{r}
m_depress <- glmer(allData$AcceptOffer ~ HRSD_NO_SUI + (1|ID), data = allData, family = binomial)
print(summary(m_depress))
```
The HRSD NO SUI factor does not influence the DV, because of the larger intercept variance than the null.

## Household income
```{r}
m_income1 <- glmer(allData$AcceptOffer ~ scale(HouseholdIncome) + (1|ID), data = allData, family = binomial)
print(summary(m_income1))
```
The household income factor does not influence the DV, because of the larger intercept variance than the null.

## Income per capita
```{r}
m_income2 <- glmer(allData$AcceptOffer ~ scale(IncomePerCapita) + (1|ID), data = allData, family = binomial)
print(summary(m_income2))

```
The income factor does not influence the DV, because of the larger intercept variance than the null.

## gender
```{r}
m_gender <- glmer(allData$AcceptOffer ~ GENDERTEXT + (1|ID), data = allData, family = binomial)
print(summary(m_gender))
```
The gender factor does not influence the DV, because of the larger intercept variance than the null.

## race
```{r}
m_race <- glmer(allData$AcceptOffer ~ RACETEXT + (1|ID), data = allData, family = binomial)
print(summary(m_race))
```
The race factor does influence the DV, because of the smaller intercept variance than the null.

## education
```{r}
m_edu <- glmer(allData$AcceptOffer ~ EDUCATION + (1|ID), data = allData, family = binomial)
print(summary(m_edu))
```
The variance is larger than the null. Education doesn't influence the DV by itself.

## marriage
```{r}
m_marriage <- glmer(allData$AcceptOffer ~ MARITALTEXT+ (1|ID), data = allData, family = binomial)
print(summary(m_marriage))
```
The variance is smaller than the null. Marriage does influence EV by itself.

## MMSE
```{r}
m_mmse <- glmer(allData$AcceptOffer ~ MMSE+ (1|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")
print(summary(m_mmse))
```
MMSE does not influence the DV by itself.

# random intercept, fixed predictors (level 1 and 2)

The global model of random intercept (1|ID) is 
```{r}
# with marriage
m_level12_interceptOnly <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + RACETEXT + GENDERTEXT + scale(EDUCATION) + scale(MMSE) + MARITALTEXT + (1|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

m_level12_interceptOnly_noMar <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + RACETEXT + GENDERTEXT + scale(EDUCATION) + scale(MMSE) + MARITALTEXT + (1|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

# without marriage
anova(m_level12_interceptOnly, m_level12_interceptOnly_noMar)

```

# Random intercept & random slope\predictors (Level 1 + Level 2)
## Simple Model(with only group predictor)
**Model**
$$logit(accept) = Reappraisal\,Direction + total\, Stake + Fairness\,score + group4$$
```{r}
# group 4
## converged successfully
m_level12_1 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + (ReappraisalDirection|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

## failed to converge
m_level12_11 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + (Fairness_score|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

## converge successfully
m_level12_12 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + (Fairness_score|ID)+ (ReappraisalDirection|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

# try all optimizers
m_level12_11_all <- all_fit(m_level12_11)
m_level12_12_all <- all_fit(m_level12_12)

# best model
anova(m_level12_1, m_level12_11)
anova(m_level12_1, m_level12_12)
anova(m_level12_11, m_level12_12)

# group5
m_level12_2 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + (ReappraisalDirection|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

m_level12_22 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + (Fairness_score|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

m_level12_23 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + (Fairness_score|ID) + (ReappraisalDirection|ID), data = allData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

m_level12_22_all <- all_fit(m_level12_22)
m_level12_23_all <- all_fit(m_level12_23)

anova(m_level12_2, m_level12_22)
anova(m_level12_2, m_level12_23)
anova(m_level12_22, m_level12_23)

# compare the model without group 4/5 predictor
anova(m_d_level1_slope1_1, m_level12_1, m_level12_2)

```
Group 4 or 5 does not make any difference to DV. Adding the clinical group does not influence the DV. So the model without the group predictor is better.

*Random effect*: The model with two random effect (Fairness_score|ID) and (ReappraisalDirection|ID) has significantly smaller AIC than the model with one random effect (ReappraisalDirection|ID) and the model with (Fairness_score|ID). But the model failed to converge at random effect (Fairness_score|ID). 

So the best model in the simple model is 
$$logit(accept) = Reappraisal\,Direction + total\, Stake + Fairness\,score + group + \\Reappraisal\, Direction|ID + Fairness\, score|ID$$

## Complex model (with all possible predictors)

**Model**
$$logit(accept) = Reappraisal\,Direction + total\, Stake + Fairness\,score + group4 + \\PROTECT2AGE + HRSD\,NO\,SUI + Household\,Income + \\RACETEXT + GENDERTEXT + marriage + MMSE + education + \\Reappraisal\,Direction|ID$$
The predictors are scaled: converted to z-scores. 

The global model with/without interation effect *(income x race)* is:
```{r}
# with intercation effect
model_level12 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) * RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (ReappraisalDirection|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

model_level121 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) * RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (Fairness_score|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

## failed to converge
model_level122 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) * RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (Fairness_score|ID) + (ReappraisalDirection|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

# all optimizers
## failed to converge
model_level122_all <- all_fit(model_level122)

anova(model_level12, model_level121)
```
With (income x race) interaction, only model with random effect (ReappraisalDirection|ID) and model with (Fairness_score|ID) successfully converged. The model with both interaction effect failed. Abandon?

```{r}
# without interaction effect
model_level12_noInter1 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (ReappraisalDirection|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

## failed to converge
model_level12_noInter11 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (Fairness_score|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

## failed to converge
model_level12_noInter12 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (Fairness_score|ID) + (ReappraisalDirection|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

# all optimizers
## failed to converge
model_level12_noInter11_all <- all_fit(model_level12_noInter11)
model_level12_noInter12_all <- all_fit(model_level12_noInter12)

# best fit models
anova(model_level12_noInter1, model_level12, model_level121)

```
*Interaction models*
The interaction model with two random effects (Fairness|ID) + (ReappraisalDirection|ID) failed to converge.

The interaction model with (ReappraisalDirection|ID) and (Fairness|ID) are not significantly differ.

The (race x income) interaction effect model is not better than the no interaction model. So use the simpler no (race x income) model.

*The types of Reappraisal Direction, Fairness_score, group4, had significant influence on the acceptance.* 

*No interaction model*
Only the model with (ReappraisalDirection|ID) successfully converged. The model with (Fairness|ID) and the model with both random effect failed to converge.

The model with interaction effect is no better than the no interaction effect. So choose the parsimonious model without (race x income) model.

The global model with/without interation effect *(income x gender)* is:

```{r}
model_level12_1 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) * GENDERTEXT + RACETEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (ReappraisalDirection|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

model_level12_11 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) * GENDERTEXT + RACETEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (Fairness_score|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

## failed to converge
model_level12_12 <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) * GENDERTEXT + RACETEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (Fairness_score|ID) + (ReappraisalDirection|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

# all optimizer
## failed to converge
model_level12_12_all <- all_fit(model_level12_12)

anova(model_level12_1, model_level12_11)
anova(model_level12_noInter1, model_level12_1)

```
The (gender x income) interaction effect model is not better than the no interaction model. So use the simpler no (gender x income) model.

*The types of Reappraisal Direction, Fairness_score, group4, had significant influence on the acceptance.* 

Maunally explore the alternative models by removing one predictor:
```{r}
# the models are named by the removed predictor
model_level12_stake <- glmer(allData$AcceptOffer ~ ReappraisalDirection + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + RACETEXT + GENDERTEXT + +scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (ReappraisalDirection|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

model_level12_age <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT +  (ReappraisalDirection|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

model_level12_HRSD <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HouseholdIncome) + RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (ReappraisalDirection|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

model_level12_income <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (ReappraisalDirection|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

model_level12_race <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (ReappraisalDirection|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

model_level12_gender <- glmer(allData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + RACETEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + (ReappraisalDirection|ID), data = allData, family = binomial, na.action = "na.fail", control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)))

anova(model_level12_noInter1, model_level12_stake, model_level12_age, model_level12_HRSD, model_level12_income, model_level12_race, model_level12_gender)

anova(model_level12_age, model_level12_HRSD, model_level12_income)
```

Explore all combinations of predictors, and list the alternatives by by the size of AIC from the small to large. The best model is selected by the smallest AIC.

The summary of all alternative models (Reappraisal Direction|ID) of the no interaction model is:
```{r} 
# random intercept and slope of Reappraisal Direction
d_model_level12 <- dredge(global.model = model_level12_noInter1, rank="AICc")
print(d_model_level12) 

## Best model
print(summary(get.models(d_model_level12,1)[[1]]))
print(summary(get.models(d_model_level12, subset = delta < 2)))
```

# Longitudinal model

1. The predictor *reappraisalDirection* is used as the time series. Recode 2 time points: 
baseline -> 1
experimental -> 2

Does participants change the acceptance over time (framing)?

```{r}

allData$framingContext <- NA
allData$framingContext[allData$ReappraisalDirection == "punish"] <- "framing"
allData$framingContext[allData$ReappraisalDirection == "empathy"] <- "framing"
allData$framingContext[allData$ReappraisalDirection == "baseline"] <- "baseline"


# random intercept, null model
m_time_null <- glmer(allData$AcceptOffer ~ framingContext + (1|ID), data = allData, family = binomial)

# random intercept and slope
m_time1 <- glmer(allData$AcceptOffer ~ framingContext + (framingContext|ID), data = allData, family = binomial)

# indepedent random effect
m_time2 <- glmer(allData$AcceptOffer ~ framingContext + (1|ID) + (0 + framingContext|ID))
summary(m_time1)
summary(m_time2)

anova(m_time_null, m_time1, m_time2)
```
The tendency of acceptance increases over time, or from baseline to framing context. 

2. Separate the framing context, use the *trial number* as the time predictor.

Does time matter in the tendency of acceptance in the framing trials?
```{r}
# in punish and empathy
framingData <- subset(allData, allData$framingContext != "baseline")

# null model
m_framing_null <- glmer(framingData$AcceptOffer ~ 1 + (1|ID), data = framingData, family = binomial)

# random intercept
m_framing_randomInter <- glmer(framingData$AcceptOffer ~ scale(Trial_Number) + (1|ID), data = framingData, family = binomial)

# random intercept and slope
m_framing_time1 <- glmer(framingData$AcceptOffer ~ scale(Trial_Number) + (Trial_Number|ID), data = framingData, family = binomial)

# HLM with indepedent random effects of intercept and slope
m_framing_time2 <- glmer(framingData$AcceptOffer ~ scale(merged_trial) + (1|ID) + (0 + merged_trial|ID), data = framingData, family = binomial)

summary(m_framing_null)
summary(m_framing_randomInter)
summary(m_framing_time1)
summary(m_framing_time2)
anova(m_framing_null, m_framing_randomInter, m_framing_time1, m_framing_time2)
```
The best fit model in the framing context is:

$$log(accept) = scale(merged\,trial) + (1|ID) + (0 + merged\,trial|ID)$$
This logitudinal model consider a model with uncorrelated random effect between $ID$ and $trial number$. Thus the model has two distinct random effects terms, each of which has $ID$ as the grouping factor:
1. 1|$ID$: intercept only
2. 0 + $trial$: slope only

However, participants were not significantly influenced by the time (trial number) in the framing context.

Does time matter in the tendency of acceptance in the baseline trials?
```{r}
baselineData <- subset(allData, allData$framingContext == "baseline")

# null model
m_base_null <- glmer(baselineData$AcceptOffer ~ 1 + (1|ID), data = baselineData, family = binomial)

# random intercept 
m_base_randomInter <- glmer(baselineData$AcceptOffer ~ scale(merged_trial) + (1|ID), data = baselineData, family = binomial)

# random intercept and slope
m_base_time1 <- glmer(baselineData$AcceptOffer ~ scale(merged_trial) + (merged_trial|ID), data = baselineData, family = binomial)

# HLM with indepedent random effect
m_base_time2 <- glmer(baselineData$AcceptOffer ~ scale(merged_trial) + (1|ID) + (0 + merged_trial|ID), data = baselineData, family = binomial)

summary(m_base_null)
summary(m_base_randomInter)
summary(m_base_time1)
summary(m_base_time2)

# comparing models
anova(m_base_null, m_base_randomInter, m_base_time1, m_base_time2)
```

The best fit model in the baseline context is:
$$log(accept) = scale(merged\,trial) + (1|ID) + (0 + merged\,trial|ID)$$
This logitudinal model consider a model with uncorrelated random effect.

Participants were significantly influenced by the time (trial number) in the baseline context.

Overall, because the participants were affected by time across the baseline condition, but not in the framing conditions, we need to run separate longitudinal models by framing and baseline: 

*Time variable*: Trial number within the framing context (punish vs. empathy)
      
## Longitudinal model 1: framing
How punish and empathy influence influence framing?

The global models are:

### random intercept, fixed predictors (level 1 and 2)

```{r}
m_long_level12_interceptOnly <- glmer(framingData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + scale(Trial_Number) + (1|ID), data = framingData, family = binomial, control = glmerControl(calc.derivs = FALSE), na.action = "na.fail")

summary(m_long_level12_interceptOnly)

```

### random intercept, random predictors (trial number)
```{r}
m_long_level12_1 <- glmer(framingData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + scale(Trial_Number) + (Trial_Number|ID), data = framingData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")
summary(m_long_level12_1)
```

### independent random intercept, random predictors (trial number)

```{r}
m_long_level12_2 <- glmer(framingData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + scale(Trial_Number) + (1|ID) + (0 + Trial_Number|ID), data = framingData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

summary(m_long_level12_2)
```

### fixed intercept, random predictors (trial number)
```{r}
m_long_level12_3 <- glmer(framingData$AcceptOffer ~ ReappraisalDirection + scale(totalStake) + Fairness_score + group4 + scale(PROTECT2AGE) + scale(HRSD_NO_SUI) + scale(HouseholdIncome) + RACETEXT + GENDERTEXT + scale(MMSE) + scale(EDUCATION) + MARITALTEXT + scale(Trial_Number) + (0 + Trial_Number|ID), data = framingData, family = binomial, control = glmerControl(calc.derivs = FALSE, optCtrl = list(maxfun = 2e4)), na.action = "na.fail")

m_long_level12_3_all <- all_fit(m_long_level12_3)
summary(m_long_level12_3)

```

## best model fit is:
```{r}
anova(m_framing_null, m_long_level12_interceptOnly, m_long_level12_1, m_long_level12_2, m_long_level12_3)
```
The best fit model is the model with *independent random intercept, random slope*.

Explore all combinations of predictors of the best fit model, and list the alternatives by by the size of AIC from the small to large. The best model is selected by the smallest AIC.

The summary of all alternative models is:
```{r}
m_d_long_level12_2 <- dredge(global.model = m_long_level12_2, rank = "AICc")
print(m_d_long_level12_2)
```

The best fit models are (delta < 2), from the smallest AIC to the largest.
```{r}
print(get.models(m_d_long_level12_2, subset = delta < 2))
```

The model with the smallest AIC in the longitudinal framing trials is 
$$logit(accept) = Fairness\,score + GENDERTEXT + group4 +  
    Reappraisal\,Direction + \\scale(totalStake) + (1 | ID) + (0 +  
    Trial_Number | ID)$$
```{r}
# the smallest AIC
d_m_long_level12_2_1 <- get.models(m_d_long_level12_2,1)[[1]]
```


## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
